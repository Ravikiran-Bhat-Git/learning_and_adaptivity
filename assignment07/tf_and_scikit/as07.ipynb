{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data from tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "mnist_one_hot = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(image, index):\n",
    "    f, ax = plt.subplots(1, len(index))\n",
    "    for i in range(len(index)):\n",
    "        ax[i].imshow(np.reshape(image[index[i]], (28,28)), cmap='Greys')\n",
    "        ax[i].set_yticklabels([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnistTwoClassifiers(object):\n",
    "    def __init__(self):\n",
    "        self.step = 100\n",
    "    \n",
    "    def update_datasets(self, train_images, train_labels, test_images, test_labels):\n",
    "        self.train_images = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.test_images = test_images\n",
    "        self.test_labels = test_labels\n",
    "    \n",
    "    def logistic_regression(self, train_size):\n",
    "        self.logistic_model = LogisticRegression()\n",
    "        print self.train_images[:train_size].shape\n",
    "        print self.train_labels[:train_size].shape\n",
    "        self.logistic_model.fit(self.train_images[:train_size], self.train_labels[:train_size])\n",
    "        return self.logistic_model\n",
    "    \n",
    "    def random_forest(self, train_size):\n",
    "        self.random_forest_model = RandomForestClassifier()\n",
    "        %time self.random_forest_model.fit(self.train_images[:train_size], self.train_labels[:train_size])\n",
    "        return self.random_forest_model\n",
    "    \n",
    "    def generate_adversarial_example(self, num_of_samples, clf, epsilon, test_images, test_labels):\n",
    "        adv_samples = np.zeros((num_of_samples, 784))\n",
    "        adv_labels = np.zeros((num_of_samples, 10))\n",
    "        adv_labels_true = np.zeros((num_of_samples, 1))\n",
    "        for i in range(num_of_samples):\n",
    "            y_predict = None\n",
    "            if clf == \"logistic_regression\":\n",
    "                y_predict = self.logistic_model.predict_proba(test_images[i:i+1])\n",
    "            elif clf == \"random_forest\":\n",
    "                y_predict = self.random_forest_model.predict_proba(test_images[i:i+1])\n",
    "        \n",
    "            y_true = test_labels[i:i+1]\n",
    "            y_true_index = np.where(y_true == 1)[1][0]\n",
    "            predictions = y_predict\n",
    "            error = (predictions - y_true)**(2)\n",
    "            error = error[0][y_true_index]\n",
    "            gradient = error * train_images[i:i+1]\n",
    "            gradient /= len(train_images[i:i+1])\n",
    "            signs = np.sign(gradient)\n",
    "            img_adversarial = epsilon * signs * test_images[i:i+1]\n",
    "            adv_samples[i] = img_adversarial\n",
    "            adv_labels[i] = y_true\n",
    "            adv_labels_true[i] = y_true_index\n",
    "        adv_samples = np.asarray(adv_samples)\n",
    "        return adv_samples, adv_labels,adv_labels_true\n",
    "        \n",
    "    def test(self, test_size, classifier):\n",
    "        if classifier == \"logistic_regression\":\n",
    "            print(self.logistic_model.score(self.test_images[:test_size], self.test_labels[:test_size]))\n",
    "        elif classifier == \"random_forest\":\n",
    "            print(self.random_forest_model.score(self.test_images[:test_size], self.test_labels[:test_size]))\n",
    "            \n",
    "    def predict(self, model, test_images, test_size):\n",
    "        return model.predict(test_images[:test_size])\n",
    "    \n",
    "    def test_with_adversarial(self, model, adv_example):\n",
    "        return model.predict(adv_example)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "test_images = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "test_labels_one_hot = mnist_one_hot.test.labels\n",
    "test_images_one_hot = mnist_one_hot.test.images\n",
    "train_labels_one_hot = mnist_one_hot.train.labels\n",
    "train_images_one_hot = mnist_one_hot.train.images\n",
    "two_clfs = mnistTwoClassifiers()\n",
    "two_clfs.update_datasets(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000,)\n",
      "CPU times: user 3.43 s, sys: 0 ns, total: 3.43 s\n",
      "Wall time: 3.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the models\n",
    "logistic_model = two_clfs.logistic_regression(55000)\n",
    "random_forest_model = two_clfs.random_forest(55000)\n",
    "clf_logistic = two_clfs.logistic_model\n",
    "clf_random_forest = two_clfs.random_forest_model\n",
    "#Save classifier to pickle file\n",
    "joblib.dump(clf_logistic, 'logistic_regression.pkl') \n",
    "joblib.dump(clf_random_forest, 'random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/logistic_regression.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-5d2c0f6de25f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogistic_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/logistic_regression.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrandom_forest_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/random_forest_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ruby/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/numpy_pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/tmp/logistic_regression.pkl'"
     ]
    }
   ],
   "source": [
    "#Load classifier\n",
    "logistic_clf = joblib.load('/tmp/logistic_regression.pkl')\n",
    "random_forest_clf = joblib.load('/tmp/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.908\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "two_clfs.test(1000, \"logistic_regression\")\n",
    "two_clfs.test(100, \"random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use test dataset\n",
    "num_adv_example = 100\n",
    "epsilon = 0.007\n",
    "adv_imgs_logistic, labels_logistic, adv_labels_true_logistic = two_clfs.generate_adversarial_example(num_adv_example, \"logistic_regression\", \\\n",
    "                                                 epsilon, test_images_one_hot, test_labels_one_hot)\n",
    "adv_imgs_rnd_forest, labels_rnd_forest, adv_labels_true_rnd_forest = two_clfs.generate_adversarial_example(num_adv_example, \"random_forest\", \\\n",
    "                                                 epsilon, test_images_one_hot, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feed adversarial example from logistic to random forest\n",
    "#clf_random_forest.predict(adv_imgs_logistic)\n",
    "clf_random_forest.score(adv_imgs_logistic, test_labels[:num_adv_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feed adversarial example from random forest to logistic model\n",
    "clf_logistic.score(adv_imgs_rnd_forest, train_labels[:num_adv_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "# Generate 55000 adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use test dataset\n",
    "num_adv_example_task_six = 55000\n",
    "epsilon_task_six = 0.007\n",
    "adv_imgs_logistic_task_six, logic_labels_task_six, logic_labels_true_task_six = two_clfs.generate_adversarial_example(num_adv_example_task_six, \"logistic_regression\", \\\n",
    "                                                 epsilon, train_images_one_hot, train_labels_one_hot)\n",
    "# adv_imgs_rnd_forest_task_six, forest_labels_task_six = two_clfs.generate_adversarial_example(num_adv_example_task_six, \"random_forest\", \\\n",
    "#                                                  epsilon, train_images_one_hot, train_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_training_set = np.concatenate((train_images,adv_imgs_logistic_task_six))\n",
    "new_training_set_label = np.concatenate((train_labels,logic_labels_true_task_six.T[0]))\n",
    "new_training_set_label_hot = np.concatenate((train_labels_one_hot,logic_labels_task_six))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_classifiers = mnistTwoClassifiers()\n",
    "adv_classifiers.update_datasets(new_training_set, new_training_set_label, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110000, 784)\n",
      "(110000,)\n"
     ]
    }
   ],
   "source": [
    "#train the models\n",
    "logistic_model_task_six = adv_classifiers.logistic_regression(new_training_set.shape[0])\n",
    "# random_forest_model_task_six = adv_classifiers.random_forest(new_training_set.shape[0])\n",
    "# clf_logistic_task_six = adv_classifiers.logistic_model\n",
    "# clf_random_forest_task_six = adv_classifiers.random_forest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909\n"
     ]
    }
   ],
   "source": [
    "adv_classifiers.test(1000, \"logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"adv_imgs_logistic\", adv_imgs_logistic_task_six)\n",
    "np.save(\"logic_labels\", logic_labels_task_six)\n",
    "np.save(\"adv_imgs_rnd_forest\", adv_imgs_rnd_forest_task_six)\n",
    "np.save(\"forest_labels\", forest_labels_task_six)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
