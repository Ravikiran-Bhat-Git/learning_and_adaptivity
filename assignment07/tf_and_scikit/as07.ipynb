{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Members\n",
    "\n",
    "## RaviKiran Bhat\n",
    "\n",
    "## Rubanraj Ravichandran\n",
    "\n",
    "## Mohammad Wasil\n",
    "\n",
    "## Ramesh Kumar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-64bc5dd34d72>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ramesh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ramesh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ramesh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ramesh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ramesh/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#Load MNIST data from tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "mnist_one_hot = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img(image, index):\n",
    "    f, ax = plt.subplots(1, len(index))\n",
    "    for i in range(len(index)):\n",
    "        ax[i].imshow(np.reshape(image[index[i]], (28,28)), cmap='Greys')\n",
    "        ax[i].set_yticklabels([])\n",
    "        ax[i].set_xticklabels([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mnistTwoClassifiers(object):\n",
    "    def __init__(self):\n",
    "        self.step = 100\n",
    "    \n",
    "    def update_datasets(self, train_images, train_labels, test_images, test_labels):\n",
    "        self.train_images = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.test_images = test_images\n",
    "        self.test_labels = test_labels\n",
    "    \n",
    "    def logistic_regression(self, train_size):\n",
    "        self.logistic_model = LogisticRegression()\n",
    "        print self.train_images[:train_size].shape\n",
    "        print self.train_labels[:train_size].shape\n",
    "        self.logistic_model.fit(self.train_images[:train_size], self.train_labels[:train_size])\n",
    "        return self.logistic_model\n",
    "    \n",
    "    def random_forest(self, train_size):\n",
    "        self.random_forest_model = RandomForestClassifier()\n",
    "        %time self.random_forest_model.fit(self.train_images[:train_size], self.train_labels[:train_size])\n",
    "        return self.random_forest_model\n",
    "    \n",
    "    def generate_adversarial_example(self, num_of_samples, clf, epsilon, test_images, test_labels):\n",
    "        adv_samples = np.zeros((num_of_samples, 784))\n",
    "        adv_labels = np.zeros((num_of_samples, 10))\n",
    "        adv_labels_true = np.zeros((num_of_samples, 1))\n",
    "        for i in range(num_of_samples):\n",
    "            y_predict = None\n",
    "            if clf == \"logistic_regression\":\n",
    "                y_predict = self.logistic_model.predict_proba(test_images[i:i+1])\n",
    "            elif clf == \"random_forest\":\n",
    "                y_predict = self.random_forest_model.predict_proba(test_images[i:i+1])\n",
    "        \n",
    "            y_true = test_labels[i:i+1]\n",
    "            y_true_index = np.where(y_true == 1)[1][0]\n",
    "            predictions = y_predict\n",
    "            error = (predictions - y_true)**(2)\n",
    "            error = error[0][y_true_index]\n",
    "            gradient = error * train_images[i:i+1]\n",
    "            gradient /= len(train_images[i:i+1])\n",
    "            signs = np.sign(gradient)\n",
    "            img_adversarial = epsilon * signs * test_images[i:i+1]\n",
    "            adv_samples[i] = img_adversarial\n",
    "            adv_labels[i] = y_true\n",
    "            adv_labels_true[i] = y_true_index\n",
    "        adv_samples = np.asarray(adv_samples)\n",
    "        return adv_samples, adv_labels,adv_labels_true\n",
    "        \n",
    "    def test(self, test_size, classifier):\n",
    "        if classifier == \"logistic_regression\":\n",
    "            print(self.logistic_model.score(self.test_images[:test_size], self.test_labels[:test_size]))\n",
    "        elif classifier == \"random_forest\":\n",
    "            print(self.random_forest_model.score(self.test_images[:test_size], self.test_labels[:test_size]))\n",
    "            \n",
    "    def predict(self, model, test_images, test_size):\n",
    "        return model.predict(test_images[:test_size])\n",
    "    \n",
    "    def test_with_adversarial(self, model, adv_example):\n",
    "        return model.predict(adv_example)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "test_images = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "test_labels_one_hot = mnist_one_hot.test.labels\n",
    "test_images_one_hot = mnist_one_hot.test.images\n",
    "train_labels_one_hot = mnist_one_hot.train.labels\n",
    "train_images_one_hot = mnist_one_hot.train.images\n",
    "two_clfs = mnistTwoClassifiers()\n",
    "two_clfs.update_datasets(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000,)\n",
      "CPU times: user 7.95 s, sys: 4.04 ms, total: 7.95 s\n",
      "Wall time: 8.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the models\n",
    "logistic_model = two_clfs.logistic_regression(55000)\n",
    "random_forest_model = two_clfs.random_forest(55000)\n",
    "clf_logistic = two_clfs.logistic_model\n",
    "clf_random_forest = two_clfs.random_forest_model\n",
    "#Save classifier to pickle file\n",
    "joblib.dump(clf_logistic, 'logistic_regression.pkl') \n",
    "joblib.dump(clf_random_forest, 'random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load classifier\n",
    "# logistic_clf = joblib.load('/tmp/logistic_regression.pkl')\n",
    "# random_forest_clf = joblib.load('/tmp/random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9198\n",
      "0.9476\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "\n",
    "two_clfs.test(test_images.shape[0], \"logistic_regression\")\n",
    "two_clfs.test(test_images.shape[0], \"random_forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Test dataset to generate Adversarial Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use test dataset\n",
    "num_adv_example = 100\n",
    "epsilon = 0.007\n",
    "adv_imgs_logistic, labels_logistic, adv_labels_true_logistic = two_clfs.generate_adversarial_example(num_adv_example, \"logistic_regression\", \\\n",
    "                                                 epsilon, test_images_one_hot, test_labels_one_hot)\n",
    "adv_imgs_rnd_forest, labels_rnd_forest, adv_labels_true_rnd_forest = two_clfs.generate_adversarial_example(num_adv_example, \"random_forest\", \\\n",
    "                                                 epsilon, test_images_one_hot, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate trained model using random forest on  adversarial examples\n",
    "clf_random_forest.score(adv_imgs_logistic, test_labels[:num_adv_example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate trained model using logistics on  adversarial examples\n",
    "clf_logistic.score(adv_imgs_rnd_forest, train_labels[:num_adv_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6\n",
    "# Generate 55000 adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use original training dataset and generate adversarial examples\n",
    "num_adv_example_task_six = 55000\n",
    "epsilon_task_six = 0.007\n",
    "adv_imgs_logistic_task_six, logic_labels_task_six, logic_labels_true_task_six = two_clfs.generate_adversarial_example(num_adv_example_task_six, \"logistic_regression\", \\\n",
    "                                                 epsilon, train_images_one_hot, train_labels_one_hot)\n",
    "adv_imgs_rnd_forest_task_six, forest_labels_task_six, forest_labels_true_task_six = two_clfs.generate_adversarial_example(num_adv_example_task_six, \"random_forest\", \\\n",
    "                                                 epsilon, train_images_one_hot, train_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_training_set = np.concatenate((train_images,adv_imgs_logistic_task_six))\n",
    "new_training_set_label = np.concatenate((train_labels,logic_labels_true_task_six.T[0]))\n",
    "new_training_set_label_hot = np.concatenate((train_labels_one_hot,logic_labels_task_six))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adv_classifiers = mnistTwoClassifiers()\n",
    "adv_classifiers.update_datasets(new_training_set, new_training_set_label, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65000, 784)\n",
      "(65000,)\n",
      "CPU times: user 10 s, sys: 108 ms, total: 10.1 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "#train the models\n",
    "logistic_model = adv_classifiers.logistic_regression(new_training_set.shape[0])\n",
    "random_forest_model = adv_classifiers.random_forest(new_training_set.shape[0])\n",
    "clf_logistic = adv_classifiers.logistic_model\n",
    "clf_random_forest = adv_classifiers.random_forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model trained on Adversarial examples and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on adversarial dataset using logistic regression\n",
      "0.9199\n"
     ]
    }
   ],
   "source": [
    "print \"Classification accuracy on adversarial dataset using logistic regression\"\n",
    "adv_classifiers.test(test_images.shape[0], \"logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on adversarial dataset using random forest\n",
      "0.9465\n"
     ]
    }
   ],
   "source": [
    "print \"Classification accuracy on adversarial dataset using random forest\"\n",
    "adv_classifiers.test(test_images.shape[0], \"random_forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does classification performance improve?\n",
    "\n",
    "Yes, classification performance of models trained on combination of adversarial examples and original dataset improves significantly\n",
    "\n",
    "\n",
    "# Is the new model less or more susceptible to adversarial examples?\n",
    "\n",
    "New model is more robust with adversarial examples because it is trained on adversarial examples also. \n",
    "\n",
    "# Do you think you can use a regularization method in order to make the model less susceptible to adversarial examples?\n",
    "\n",
    "No, state of the art shows that Generic regularization strategies such as dropout, pretraining, and model averaging do not confer a significant reduction in a model’s vulnerability to adversarial examples, but changing\n",
    "to nonlinear model families such as RBF networks can do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(\"adv_imgs_logistic\", adv_imgs_logistic_task_six)\n",
    "# np.save(\"logic_labels\", logic_labels_task_six)\n",
    "# np.save(\"adv_imgs_rnd_forest\", adv_imgs_rnd_forest_task_six)\n",
    "# np.save(\"forest_labels\", forest_labels_task_six)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
